---
title: "JMJPFU-CelltraqProcess"
output: html_notebook
---

# JMJPFU
### 20-Feb-2017

This is the end to end process with all the scripts for creating a prediction model for Celltraq. This involves the following

1. Getting the inputs
2. Consolidating the inputs
3. Cleaning the input and creating the consolidated dataset
4. Feature engineering the consolidated data set for exploratory analysis and modelling
5. Exploratory analysis 
6. Model training with the feature engineered dataset and calculating the baseline metrics
7. Deploying the models on to the platform of choice
8. Giving predictions as Rest API's from the deployment platform to the client system
9. Continuous training of the model,model improvement and re-deployment



### Step 1 : Loading all the library Files

In this step all the library files required for the end to end process are loaded

```{r}
library(dplyr)
library(ggplot2)
library(caret)
library(caretEnsemble)



```


### Step 2 : Getting the input files


#### Step 2.a : Listing all the input files

The input files for Celltraq are received as csv files. The csv files are consolidated and received as specific files for each parameter. Below are the details about the input files

1. Conductance : 2 Files with names ( "Battery Conductance I.csv")
2. Voltage and Current : Multiple files with names starting with  ( "Battery Discharge I.csv" )
3. Voltage and Temperature : Multiple files with names starting with ("Battery Voltage Temperature I.csv")


Process for loading the Files

1. Load each type of file in seperate folder ( Seperate folder for Conductance, Seperate folder for Discharge, Seperate folder for volt temp)
2. Conductance data has 15 variables, Discharge has 12 variables and volt temp has 20 variables
3. Create an empty dataframe with names as per the list of variables in the excel sheet
4. Get the list of files in each folder
5. Run over the list as an iterator and read each file using read_csv and store each file into a temperory variable. The names of the temperory variable has to be the same as the number of columns in the excel sheet.
6. Rbind each of the read temperory file with the empty dataframe which was created.
7. This will create a consolidated data frame for each of the variables.



Points to be noted :

1. How would the input files be given from Celltraq ?
2. Where will it be stored ?
3. What format will it be stored ?
4. Will the format change from time to time ?
5. Will any of the columns change from time to time ?
6. Will the seperator within the data change in future ?

#### Step 2.B : Loading the input data sets into the system

The next steps are to load the input files into the system. Listed below are the scripts to load the data


```{r}

# Conductance Files

condFile1 <- "Battery Conductance I.csv" # Name of files
condFile2 <- "Battery Conductance II.csv"

path1 <- paste0("C:/Toms/customers/Celltraq/excelfiles/Conductance/",condFile1) # Path of files
path2 <- paste0("C:/Toms/customers/Celltraq/excelfiles/Conductance/",condFile2)


condDf1 <- read.csv(path1,sep="|",header=FALSE)
condDf2 <- read.csv(path2,sep="|",header=FALSE)

# Naming the columns

names(condDf1) <- names(condDf2) <- c("Unique_ID","Site_Name","Plant_Name","String_Name","Battery_no","Measurement_Timestamp","Conductance","Conductance_High_Alarm","Conductance_High_Warning","Conductance_Low_Warning","Conductance_Low_Alarm","Manufacturer","Model","Battery_Type","Battery_Voltage")

# The first row of each of the data frames the battery id is distorted

condDf1$Unique_ID[1] <- paste(condDf1$Unique_ID[2])

condDf2$Unique_ID[1] <- paste(condDf2$Unique_ID[2])

# Merging both the files

condDf <- rbind(condDf1,condDf2)

```

Reading the Battery discharge data. The number of files are large. So have to set a path and read in the data

```{r}

# Discharge Files

filename <- list.files(path = "C:/Toms/customers/Celltraq/excelfiles/Discharge")
# Creating an empty data frame
dischargeDf1 <- data.frame(matrix(nrow=0,ncol= 12)) # Creating an empty data frame
colnames(dischargeDf1) <- c("Unique_ID","Site_Name","Plant_Name","String_Name","Battery_no","Measurement_Timestamp","Voltage","Current","Manufacturer","Model","Battery_Type","Battery_Voltage"  )# Naming the data frame

for(i in 1:2){
  
  temppath <- paste0("C:/Toms/customers/Celltraq/excelfiles/Discharge/",filename[i])
  
  temp_discharge <-  read.csv(temppath,sep="|",header=FALSE) # Reading in the file
  temp_discharge[1,1] <- paste(temp_discharge[2,1]) # The first record for battery id is always in a bad format. So repasting from the second record
  colnames(temp_discharge) <- c("Unique_ID","Site_Name","Plant_Name","String_Name","Battery_no","Measurement_Timestamp","Voltage","Current","Manufacturer","Model","Battery_Type","Battery_Voltage"  ) # naming the data frame
  dischargeDf1 <- rbind(dischargeDf1,temp_discharge) # Condolidating data from each file
  
} # End of for loop for consolidating all the data

```

### Points to be noted
1. How do we ensure scalability as the data points are large for the discharge data ?
2. Do we consolidate all data into one DF or multiple DFs ?
3. What are the challenges when the number of records keep on growing ?
4. Can we eliminate the old data ? Or keep them into a storage for future use ?
5. Ideally the prediction job is done once in three months, so do we store all the required data for three months in one DF ?
6. If the format of the csv is changed then the read_csv in line 94 has to be changed.


```{r}
# Voltage and Temperature files

volttempDf1 <- data.frame(matrix(nrow=0,ncol= 20))

colnames(volttempDf1) <- c("Unique_ID","Site_Name","Plant_Name","String_Name","Battery_no","Measurement_Timestamp","Voltage","Voltage_High_Alarm","Voltage_High_Warning","Voltage_Low_Warning","Voltage_Low_Alarm","Temperature","Temperature_High_Alarm","Temperature_High_Warning","Temperature_Low_Warning","Temperature_Low_Alarm","Manufacturer","Model","Battery_Type","Battery_Voltage" )

filename <- list.files(path = "C:/Toms/customers/Celltraq/excelfiles/VoltageTemp")


for(i in 1:2){
  
  temppath <- paste0("C:/Toms/customers/Celltraq/excelfiles/VoltageTemp/",filename[i])
  
  temp_voltemp <-  read.csv(temppath,sep="|",header=FALSE)
  temp_voltemp[1,1] <- paste(temp_voltemp[2,1])
  colnames(temp_voltemp) <- c("Unique_ID","Site_Name","Plant_Name","String_Name","Battery_no","Measurement_Timestamp","Voltage","Voltage_High_Alarm","Voltage_High_Warning","Voltage_Low_Warning","Voltage_Low_Alarm","Temperature","Temperature_High_Alarm","Temperature_High_Warning","Temperature_Low_Warning","Temperature_Low_Alarm","Manufacturer","Model","Battery_Type","Battery_Voltage" )
  volttempDf1 <- rbind(volttempDf1,temp_voltemp)
}



```

Notes
1. How do we tackle the scalability of the data? The number of values can be large.
2. How often do we consolidate this data ?
3. Do we create a data store to store all these data points ? Ideally a data store should be made which should be leveraged later.
4. How do we ensure that all the columns required are there ? 
5. How do we ensure that the column names do not change.
6. How do we deal if a new data column is introduced ?
7. What is the source for these files ? 
8. In what format will these files be received ?
9. Will the structure of the data change ?
10. Do we need to change the data read method if a common data store is fixed to dump the data.
11. Understand the process by which the data points are generated from the measuring devices.

### Step 3 : Removing the outliers from the data

Some data points might have outlier values. These have to be removed. Below is the process for getting that done.



```{r}
# Eliminating outliers from Conductance values
condDf1 <- condDf1 %>% filter(Conductance < 10000)
condDf2 <- condDf2 %>% filter(Conductance < 10000)

# Eliminating outliers from Discharge
dischargeDf1 <- dischargeDf1 %>% filter(Current < 50 & Current > 0)


# Eliminating outliers from volt-temp variable

```



#### Step 4: Consolidating all the variables of each battery in a single data frame

The purpose of this step is to get a consolidated dataset for each battery accross the three key metrics i.e - Conductance, Discharge and Volt temp. A consolidated data set for each battery will also serve the purpose of good visualisations accross each battery accross the various periods. This can be taken as a micro service later on.

The various variables that are involved in the process are the following

1. Conductance - From the seperate file for conductance
2. Discharge - From the seperate file for discharge
3. Volttemp - From the seperate file for Volttemp
4. Discharge - Whether the voltage slope is for discharge or charge. This is a derived variable. Process explained below
5.Charge - Whether the voltage slope is for discharge or charge. A derived variable. Process explained below
6. DOD - Depth of discharge. A derived variable. Process explained below
7. Temperature - From seperate file for Volttemp
8. Voltage - Normal voltage. From seperate file for Volttemp


Process for the complete procedure

1. Create a list of batteries for which the consolidated dataframe needs to be created. This list can be taken from the unique list of all batteries for the client involved. ( lines : 187:). This list has to be made as a dataframe as step 3 requires a dataframe to loop over and get batteries
2. Create an empty dataframe with 9 columns. This data frame is to consolidate the variables of each battery, one by one. The names of the columns are as per line 214
3. Start an iterative loop to loop over the complete list of batteries as mentioned in step 1. The purpose of this loop is to take one battery at a time and then extract the required features of the batteries from the respective variable files ( Conductance, Discharge & Volt temp). The process inside the iterative loop is as follows
  3.1 : Store the battery as per the iterative list in a variable. The battery ID will be read from the battery list created         in step 1
  3.2 : In the second step a seperate function is called 'bat_select'. The process of what the function achieves is as per           the function notebook 'Celltraq_NewFunctions'. The output from this process is a dataframe containing 5 variables (          Timestamp, Variable, Measure, Date, Date1). The Measure variable will have five different values      (Conductance,Voltage,Current,Temperature,Volttemp)
  3.3 : Once the battery variables are consolidated, the NA values are eliminated 
  3.4 : The next step in the process is to consolidate other variables related to the voltage like the Charge, Discharge and         depth of discharge profiles from the voltage profiles. This is done through the function called "bat_features". For           running the function, 4 variables are required.
        1 - A variable called bt. This is got by finding number of instances where the discharge readings are taken
        2 - bat_test : The real dates where the discharge readings are taken. This is got from the bat_conall dataframe
        3 - bat_conall : The complete battery data consolidated in step 3.2
        4 - float_volt : This is the float voltage value for the relevant type of battery which is passed.
        The details of the process under the function "bat_features" is described in the functions notebook.
        The output from running the function is a data frame with 5 variables with the measures like ( Charge, discharge and         DOD)
  3.5 : The output from the "bat_features" function has to be consolidated with the other features extracted with the other          steps.
  3.6 : Along with the extracted features, other details like the "battery", "site","string" etc are also added to the              dataframe.
4. Once all the details are extracted, the final consolidated data frame is derived
  
       



```{r}
# Creating the list of batteries

batList <- list(unique(condDf1$Unique_ID),unique(condDf2$Unique_ID))

batList <- unlist(batList[[1]],batList[[2]])

batList <- data.frame(batList)
names(batList) <- "Battery"

```


# JMJPFU
# 24-Feb-2017

Let us now take a sample of batteries from the data created so far to test the complete process. The process for taking the batteries is as follows

1. Compare all the three varaible files and take only the batteries present in all the three files.

```{r}
disbat <- data.frame(unique(dischargeDf1$Unique_ID))
disbat$dispresent <- 1
names(disbat) <- "Battery"

# Batteries in volttemp dataframe

voltbat <- data.frame(unique(volttempDf1$Unique_ID))
names(voltbat) <- "Battery"
voltbat$volpresent <- 2

# Merging all three files

batSample <- merge(batList,disbat,all.x = TRUE) # First merging with the discharge list

batSample <- merge(batSample,voltbat,all.x = TRUE) # Next merging with the voltage list

batSample$total <- batSample$dispresent + batSample$volpresent # Finding a total where both are present

# Filtering the relevant batteries

batRelevant <- batSample %>% filter(total==3) %>% select(Battery) 

# Replacing the batList variable with batRelevant data

batList <- batRelevant

```




```{r}

# The complete data frame for calculating the new data frame

batConsolidated <- data.frame(matrix(nrow=0,ncol=9)) # 25 Oct bat_newfeat5 > batConsolidated

colnames(batConsolidated) <- c( "Measurement_Timestamp","Variable","measure","Date","Date1","Battery","Plant","Site","String")

# Looping over the data frame of the batteries where the required trend is required

for(i in 1:nrow(batList)){ 
  
  # First get the battery
  battery <- paste(batList[i,1]) # batdf1 > batList
  
  # Get the consolidated data for all batteries from the function bat_select 
  bat_conall <- bat_select(battery,condDf,dischargeDf1,volttempDf1) 
  
  # Removing any NA values from the battery data frame
  
  bat_conall <- bat_conall[complete.cases(bat_conall),]
  
  # Finding all the dates where the voltage discharge profile is calculated
  
  bat_test <- unique(bat_conall %>% filter(measure=="Voltage") %>% select(Date))

  bt <- nrow(unique(bat_conall %>% filter(measure=="Voltage") %>% select(Date)))
  
  # Getting the voltage data for further calculating the charge and Discharge data
  
  volt_mean <- bat_conall %>% filter(measure=="Voltage") %>% select(Variable)
  
  # Finding the mean value of the voltage for the battery
  
  fv <- floor(mean(volt_mean$Variable,na.rm = TRUE))
  
  # Finding the float voltage based on teh battery type
  
  ifelse(fv < 5,float_volt <- 2.23,float_volt <- 13.4)  # Setting the float voltage
  
  # Getting additional features of the battery by running the function bat_features
  
  bat_sub <- bat_features(bt,bat_test,bat_conall,float_volt) # Function to get other features
  
  # Consolidating all the data
  
  bat_conall <- rbind(bat_conall,bat_sub) 
  
  # Consolidating other data elements like "battery" , "Site_name", "Plant_name","String_name" etc
  
  bat_conall$Battery <- battery 
  
  bat_others <- unique(filt1 %>% filter(Unique_ID == battery) %>% select(Site_Name,Plant_Name,String_Name))
  
  bat_conall$Plant <- bat_others$Plant_Name
  bat_conall$Site <- bat_others$Site_Name
  bat_conall$String <- bat_others$String_Name
  
  # Combining all the data together
  
  batConsolidated <- rbind(batConsolidated,bat_conall)
  
  # Printing the iterator
  
  print(i)
  
  
} # End of the iteration to loop over the list of all batteries



```

# JMJPFU
### 28-Feb-2017

### Step5 : Creating the dataframe for training and validation

The next step is to take the consolidated data frame and prepare the data set for training the model. There are two subprocesses for this case.

1. Prepare the training set and validation set as per the period model
2. Filter failure cases from the consolidated data set prepared earlier and then label the training set 

The reason why the second step is necessary is because, in the case of celltraq there was no labelling of data. Because of this we have to resort to data exploration and get the failed cases of batteries.

First we will get into the process of preparing the validation set.

# JMJPFU
### 2-Mar-2017

### Step 5.a : Preparing the training set and validation set in the proper format

The process for creating the training set from the consolidated data set as defined earlier is as follows

1. Create an empty dataframe which can have 16 columns. The 16 coloumns are decided based on the number of variables that are to be included in the model. Once the variables change the number of columns also change. The names of the variables are also defined in the beginning.
2. The explanation of the variable names are as follows
      featDischarge : This is the mean value of the discharge values of the voltage. 
      conSlope : This is the slope of the conductance values. The slope is calculated by running a linear model for the                       conductance data
      dodMin : This is the minimum value of the depth of discharge between the date ranges. 
      Dod50 : This is the % of values between the date ranges analysed which show values less than 50% of dept of discharge
      Dod85 : This is the % of values between the date ranges which have values between 50% and 85 %
      Dodtop : This is the % of values which have dod values greater than 85%
      conDrop : This is the % drop of, the mean value of conductance between two date ranges, from the maximum value within the same date range
      con50 : This is the % of values within a date range which are less than 50% of value of the maximum conductance value of the battery
      con80 : This is the % of values within a date range which is between 50% and 85% of the maximum conductance values
      contop : This is the % of values within a date range which falls above 85% of the maximum conductance values of the battery
      voltSD : This is the standard deviation of the voltage between the date ranges.
      Battery : The unique id of the battery for which the features are extracted
      Counter : A counter indicating the number of records which will be there for a battery. This is also an indicator of the period when the data is extracted. This will not be used for modelling
      Bench1 : The benchmark date 1 which will be the lower bound date for the date range
      Bench2 : The benchmark date 2 which will be the upper bound date for the date range
      label : labels which will be created for the data frame
      
3. After creating the empty data frame for aggreagating data on the features, a new iterative loop is initiated to start the process of consolidating data. The process within the iterative loop is as follows

  3.1 : Each battery is listed one by one as per the iterative loop.
  3.2 : The function called "batFeat1" is run to get the training features. The process for "batFeat1" is explained seperately in the functions notebook - "Celltraq_NewFunctions.Rmd". One check which has to be done is that the battery which is being passed into the function has to be present in the consolidated data of the battery. If the battery is not present in the consolidated data frame then the function call will fail. Or this check has to be made in the calling function.
  3.3 : The data which is returned from the function "batFeat1" will have 15 columns and the number of rows will be almost equal to the number of dates generated from the "dateLister" function used in "batFeat1"
  
4. After the data from the "batFeat1"  function is extracted, a new columns for indicating the label of the data is created for the dataframe. The label feature is first initialised as "NA"

5. The next steps is to do some labelling for the data set. We are making an assumption that the first 2/3 of the rows for a battery will be normal and the last 1/3 of the rows can be tested to check if failure is present. So finally when the training data set is created, the first 2/3 data will be taken with labels as "Normal Period". This will be joined with data from the problematic batteries with labels related to periods of failuer. This will be explained later on

6. The last 1/3 of data will be labelled as "To-test" and this will form our testing data.
7. Finally all the records are attached to the empty data frame created in step 1





```{r}

trainCon <- data.frame(matrix(nrow=0,ncol=16)) # normalCon > trainCon

names(trainCon) <- c("featDischarge","conSlope","dodMin","Dod50","Dod85","Dodtop","conDrop","con50","con80","contop","voltSD","Battery","Counter","Bench1","Bench2","label" )

# An iterative loop is initiated to go over the list of the batteries for which new data frame has to be created

for(i in 1: nrow(normalBats)){
  # normalBats : This is the list of batteries for which the new data frame has to be created
  
  # Listing one battery at a time
  bat2Exp <- normalBats$Battery[i]
  
  # Running the function batFeat1. 

featTest2  <- batFeat1(bat2Exp,batConsolidated,3) # bat_newfeat5 > batConsolidated

 # A counter is started 
  
cou = 0

# A new column for labels is created and set to NA

featTest2$label <- NA # Setting up a label

# Finding the first 2/3 of data and the rest data

labRec <- round(nrow(featTest2) * 2/3)

testRec <- nrow(featTest2) - labRec

# Loops for creating labels

for(j in 1:testRec){
  
  featTest2$label[j] <- "To_test"
} # End of to be tested period for loop records

for(k in (testRec+1):nrow(featTest2)){
  
  featTest2$label[k] <- "Normal_Period"
  
} # End of Normal period records for loop

# Imputing mean values for NA values in conductance slope

featTest2[is.na(featTest2$conSlope),2] <- mean(featTest2$conSlope,na.rm = TRUE) # Imputing mean values NA conslope values



trainCon <- rbind(trainCon,featTest2) # Creating a consolidated dataframe



} # End of the iterative loop to go over the list of batteries


```

# JMJPFU
### 6-Mar-2017

### Step 6 : Filtering out the Potential Failed cases

This is a unique step for this problem. Since there were no labels for the data, we had to filter out the problem cases where the batteries were failing. The below process is to achieve that. Once the problem cases are filtered, we will filter out the relvant batteries from the "trainCon" dataframe created about in step 5 and then label those batteries seperately.

The process for this step are as follows

1. The first step is to take a list of batteries which needs to be analysed. This is taken from the consolidated battery data created from step-4. The unique list of batteries present in the consolidated battery data is taken.

2. In the next step, a function called "batFeat" is run to extract features for the list of batteries generated from step1 above. The variables that have to be fed for the function are the "batList > which is the list of batteries in the consoldiated battery data frame" and "batConsolidated > which is the consolidated data for all batteries". The detailed process for "batFeat" function is explained in the "NewFunctions" Notebook. The output from this step is a dataframe with 65 variables. The number of rows will be equal to the number of batteries in the list of batteries supplied to the function

3. After the above step, a third function is run on the output of step 2 to include some more additional features. This can be a redundant step. If we can consolidate this function with the "batFeat" function, we can avoid one step. The new function is named "batFeatAddn". The detailed process for this function is explained in the Newfunction notebook.

4. The last step is to run another function called condropFeat. This function is to identify those cases which have failure indicating drop in conductance. There are two outputs from this function. 
  1. One is a data frame with number of records as there are batteries. There are two columns for this dataframe. One column       is the battery id and the second column is the consolidated fail drop value. The number of rows of this data frame will be equal to the number of batteries in the list
  2. The second data frame is a consolidated data set with all the values of conductance along with the classification            whether the drop is a normal or failed drop etc. This data frame will have 4 columns and will have multiple rows for each battery. The number of rows for each battery will be equal to the number of conductance values present for each battery.
  



```{r}

# The below function creates the required details

batList <- unique(batConsolidated %>% select(Battery,Plant,Site,String)) # bat_newfeat5 > batConsolidated

# batList to be given as a dataframe

batteryFeatures <- batFeat(batList,batConsolidated) # Creates the required Feature map

# Run another function to create another set of features

batteryFeatures <- batFeatAddn(batteryFeatures,batConsolidated)

# Running another function to create the new set of features for condropFeat # batlist > batList

conlist <- condropFeat(batList$Battery,batConsolidated,0.1,0.3) # thresh2 values of 1 resulted in a clean set of potential failure cases

# Getting the individual data frames from the function

test1 <- conlist$result1 
test2 <- conlist$result2

# The condrop features to be merged with existing features

batteryFeatures <- merge(batteryFeatures,test1,all.x = TRUE)

# Selecting a limited list of features

batFeatTrain <- batteryFeatures %>% select(Battery,PD1sl,PD2sl,PD3sl,PD4sl,PD5sl,PD6sl,PD7sl,PD8sl,PD9sl,PD10sl,Condrop,Dodtop,Dod80,Dod50,contop,con80,con50,FailDrop)

```







 
  



















### Points to be carried over
1. In the production environment, do we create seperate models for each client ? Or do we do the modelling based on the consolidated data for all clients ?


## JMJPFU
## 22-Feb-2017
1. Continue with the process creation
2. Complete with the end to end process
3. List down the process of all functions
4. List out the processes which have to be developed with other methods and which have to be done in R
5. List out methods for accessing R models
6. List out frequency of R model creation
7. List out frequency of how each file is created and accessed
8. List out what would be the output in the final client dashboard
9. Decide weather client specific model has to be created or a consolidated model for all data.


# Tomorrow
1. start with line 444 in the NewFunction notebook